{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Network (VGG-19) Implemetation\n",
    "\n",
    "\n",
    "## Architecture: \n",
    "\n",
    "![ConvNet Configration](<./img/VGG-19 Very Deep Convolutional Networks/Screenshot 2024-06-23 at 2.24.38â€¯PM.jpg>)\n",
    "\n",
    "\n",
    "[Very Deep Convolutional Networks for Large Scale Image Recognition Paper](https://arxiv.org/abs/1409.1556)\n",
    "\n",
    "Key Libraries and Classes in PyTorch\n",
    "\n",
    "1. _**torch.nn**_: This module provides all the building blocks to build neural networks, such as layers loss functions, and activation functions.\n",
    "   1. nn.Conv2d: To define convolutional layers.\n",
    "   2. nn.MaxPool2d: To define max-pooling layers.\n",
    "   3. nn.Linear: To define fully connected layers.\n",
    "   4. nn.ReLU: For activation functions.\n",
    "   5. nn.Sequential: To stack layers sequentially.\n",
    "   6. nn.BatchNorm2d: (Optional) To add batch normalization layers.\n",
    "2. _**torch.optim**_: This module includes various optimization algorithms. \n",
    "   1. optim.SGD: For stochastic gradient descent optimizer.\n",
    "   2. optim.Adam: For Adam optimizer.\n",
    "   3. transforms.Compose: To combine multiple transformations.\n",
    "3. _**torchvision.transforms**_: This module provides common image transformations.\n",
    "   1. transforms.ToTensor: To convert images to PyTorch tensors.\n",
    "   2. transforms.Normalize: To normalize image pixel values.\n",
    "4. _**torchvision.datasets**_: This module provides easy access to popular datasets.\n",
    "   1. datasets.CIFAR10: To load the CIFAR-10 dataset.\n",
    "5. _**torch.utils.data.DataLoader**_: This utility helps in creating data loaders to iterate over datasets. DataLoader: To create data loaders for training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch import device, backends\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# Using the GPU for pytorch lib (Its called MPS in case of Macbook)\n",
    "device = device(\"mps\") if backends.mps.is_available() else device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define transformations for the training and test sets\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "data_dir = \"./datasets/CIFAR10\"\n",
    "\n",
    "# Download and load the training dataset\n",
    "trainset = datasets.CIFAR10(\n",
    "    root=data_dir, train=True, download=True, transform=transform\n",
    ")\n",
    "train_loader = DataLoader(dataset=trainset, batch_size=32, shuffle=False, num_workers=4)\n",
    "# trainset.data.shape, trainset.data.dtype\n",
    "train_loader.dataset.__getitem__(1)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((10000, 32, 32, 3), dtype('uint8'), torch.Size([3, 32, 32]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading test data using the pytorch Lib\n",
    "testset = datasets.CIFAR10(\n",
    "    root=data_dir, train=False, download=True, transform=transform\n",
    ")\n",
    "test_loader = DataLoader(dataset=testset, batch_size=32, shuffle=True, num_workers=4)\n",
    "\n",
    "testset.data.shape, testset.data.dtype, test_loader.dataset.__getitem__(1)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Architecture for VGG-19 , \n",
    "# This can be modified to implement other VGG-networks\n",
    "VGG19 = [\n",
    "    64,\n",
    "    64,\n",
    "    \"M\",\n",
    "    128,\n",
    "    128,\n",
    "    \"M\",\n",
    "    256,\n",
    "    256,\n",
    "    256,\n",
    "    256,\n",
    "    \"M\",\n",
    "    512,\n",
    "    512,\n",
    "    512,\n",
    "    512,\n",
    "    \"M\",\n",
    "    512,\n",
    "    512,\n",
    "    512,\n",
    "    512,\n",
    "    \"M\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "\n",
    "class VGGNet(nn.Module):\n",
    "    def __init__(self, in_channel=3, num_classes=1000, architecture=VGG19) -> None:\n",
    "        super(VGGNet, self).__init__()\n",
    "        self.in_channel = in_channel\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        \n",
    "        self.conv_layers = self.create_conv_layer(architecture=architecture)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fcl = nn.Sequential( \n",
    "            nn.Linear(512 * 1 * 1, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = self.fcl(x)\n",
    "        return x\n",
    "\n",
    "    def create_conv_layer(self, architecture):\n",
    "        layers = []\n",
    "        in_channels = self.in_channel\n",
    "\n",
    "        for x in architecture:\n",
    "            if isinstance(x, int):\n",
    "                out_channels = x\n",
    "                layers += [\n",
    "                    nn.Conv2d(\n",
    "                        in_channels=in_channels,\n",
    "                        out_channels=out_channels,\n",
    "                        kernel_size=3,\n",
    "                        padding=1,\n",
    "                        stride=1,\n",
    "                    ),\n",
    "                    nn.BatchNorm2d(x),  # Not in the original paper, but it will improve performance.\n",
    "                    nn.ReLU(inplace=True),\n",
    "                ]\n",
    "                in_channels = x  # for the next layer the in_channels is x\n",
    "            else:\n",
    "                layers += [nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))]\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGGNet(\n",
      "  (conv_layers): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace=True)\n",
      "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (32): ReLU(inplace=True)\n",
      "    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (35): ReLU(inplace=True)\n",
      "    (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (38): ReLU(inplace=True)\n",
      "    (39): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (42): ReLU(inplace=True)\n",
      "    (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (45): ReLU(inplace=True)\n",
      "    (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (48): ReLU(inplace=True)\n",
      "    (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (51): ReLU(inplace=True)\n",
      "    (52): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fcl): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=4096, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = VGGNet(in_channel=3, num_classes=10, architecture=VGG19)\n",
    "# .to(device=device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "standard_input = torch.randn((2, 3, 224, 224))\n",
    "# .to(device=device)\n",
    "print(model(standard_input).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1561,  0.3339,  0.0030, -0.0989,  0.2904,  0.0321,  0.3056,  0.0332,\n",
       "          0.1084, -0.0330],\n",
       "        [ 0.1498,  0.1961,  0.1103,  0.0616,  0.0101, -0.2051,  0.1965,  0.0625,\n",
       "         -0.0553,  0.0426]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(standard_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# .to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch 100] loss: 2.392\n",
      "[Epoch 1, Batch 200] loss: 2.288\n",
      "[Epoch 1, Batch 300] loss: 2.240\n",
      "[Epoch 1, Batch 400] loss: 2.149\n",
      "[Epoch 1, Batch 500] loss: 2.091\n",
      "[Epoch 1, Batch 600] loss: 2.039\n",
      "[Epoch 1, Batch 700] loss: 1.980\n",
      "[Epoch 1, Batch 800] loss: 1.983\n",
      "[Epoch 1, Batch 900] loss: 1.989\n",
      "[Epoch 1, Batch 1000] loss: 1.954\n",
      "[Epoch 1, Batch 1100] loss: 1.979\n",
      "[Epoch 1, Batch 1200] loss: 1.963\n",
      "[Epoch 1, Batch 1300] loss: 1.956\n",
      "[Epoch 1, Batch 1400] loss: 1.956\n",
      "[Epoch 1, Batch 1500] loss: 1.922\n",
      "[Epoch 2, Batch 100] loss: 2.008\n",
      "[Epoch 2, Batch 200] loss: 1.958\n",
      "[Epoch 2, Batch 300] loss: 1.949\n",
      "[Epoch 2, Batch 400] loss: 2.000\n",
      "[Epoch 2, Batch 500] loss: 1.958\n",
      "[Epoch 2, Batch 600] loss: 1.955\n",
      "[Epoch 2, Batch 700] loss: 1.882\n",
      "[Epoch 2, Batch 800] loss: 1.880\n",
      "[Epoch 2, Batch 900] loss: 1.925\n",
      "[Epoch 2, Batch 1000] loss: 1.903\n",
      "[Epoch 2, Batch 1100] loss: 1.993\n",
      "[Epoch 2, Batch 1200] loss: 1.937\n",
      "[Epoch 2, Batch 1300] loss: 1.883\n",
      "[Epoch 2, Batch 1400] loss: 1.872\n",
      "[Epoch 2, Batch 1500] loss: 1.889\n",
      "[Epoch 3, Batch 100] loss: 1.895\n",
      "[Epoch 3, Batch 200] loss: 1.894\n",
      "[Epoch 3, Batch 300] loss: 1.850\n",
      "[Epoch 3, Batch 400] loss: 1.887\n",
      "[Epoch 3, Batch 500] loss: 1.891\n",
      "[Epoch 3, Batch 600] loss: 1.847\n",
      "[Epoch 3, Batch 700] loss: 1.800\n",
      "[Epoch 3, Batch 800] loss: 1.803\n",
      "[Epoch 3, Batch 900] loss: 1.809\n",
      "[Epoch 3, Batch 1000] loss: 1.818\n",
      "[Epoch 3, Batch 1100] loss: 1.795\n",
      "[Epoch 3, Batch 1200] loss: 1.823\n",
      "[Epoch 3, Batch 1300] loss: 1.816\n",
      "[Epoch 3, Batch 1400] loss: 1.781\n",
      "[Epoch 3, Batch 1500] loss: 1.788\n",
      "[Epoch 4, Batch 100] loss: 1.788\n",
      "[Epoch 4, Batch 200] loss: 1.785\n",
      "[Epoch 4, Batch 300] loss: 1.738\n",
      "[Epoch 4, Batch 400] loss: 1.726\n",
      "[Epoch 4, Batch 500] loss: 1.707\n",
      "[Epoch 4, Batch 600] loss: 1.718\n",
      "[Epoch 4, Batch 700] loss: 1.661\n",
      "[Epoch 4, Batch 800] loss: 1.670\n",
      "[Epoch 4, Batch 900] loss: 1.670\n",
      "[Epoch 4, Batch 1000] loss: 1.648\n",
      "[Epoch 4, Batch 1100] loss: 1.651\n",
      "[Epoch 4, Batch 1200] loss: 1.637\n",
      "[Epoch 4, Batch 1300] loss: 1.633\n",
      "[Epoch 4, Batch 1400] loss: 1.626\n",
      "[Epoch 4, Batch 1500] loss: 1.601\n",
      "[Epoch 5, Batch 100] loss: 1.632\n",
      "[Epoch 5, Batch 200] loss: 1.595\n",
      "[Epoch 5, Batch 300] loss: 1.583\n",
      "[Epoch 5, Batch 400] loss: 1.570\n",
      "[Epoch 5, Batch 500] loss: 1.579\n",
      "[Epoch 5, Batch 600] loss: 1.552\n",
      "[Epoch 5, Batch 700] loss: 1.517\n",
      "[Epoch 5, Batch 800] loss: 1.494\n",
      "[Epoch 5, Batch 900] loss: 1.516\n",
      "[Epoch 5, Batch 1000] loss: 1.454\n",
      "[Epoch 5, Batch 1100] loss: 1.505\n",
      "[Epoch 5, Batch 1200] loss: 1.502\n",
      "[Epoch 5, Batch 1300] loss: 1.432\n",
      "[Epoch 5, Batch 1400] loss: 1.422\n",
      "[Epoch 5, Batch 1500] loss: 1.435\n",
      "[Epoch 6, Batch 100] loss: 1.470\n",
      "[Epoch 6, Batch 200] loss: 1.428\n",
      "[Epoch 6, Batch 300] loss: 1.383\n",
      "[Epoch 6, Batch 400] loss: 1.370\n",
      "[Epoch 6, Batch 500] loss: 1.354\n",
      "[Epoch 6, Batch 600] loss: 1.325\n",
      "[Epoch 6, Batch 700] loss: 1.343\n",
      "[Epoch 6, Batch 800] loss: 1.307\n",
      "[Epoch 6, Batch 900] loss: 1.315\n",
      "[Epoch 6, Batch 1000] loss: 1.279\n",
      "[Epoch 6, Batch 1100] loss: 1.290\n",
      "[Epoch 6, Batch 1200] loss: 1.283\n",
      "[Epoch 6, Batch 1300] loss: 1.260\n",
      "[Epoch 6, Batch 1400] loss: 1.245\n",
      "[Epoch 6, Batch 1500] loss: 1.263\n",
      "[Epoch 7, Batch 100] loss: 1.226\n",
      "[Epoch 7, Batch 200] loss: 1.229\n",
      "[Epoch 7, Batch 300] loss: 1.209\n",
      "[Epoch 7, Batch 400] loss: 1.211\n",
      "[Epoch 7, Batch 500] loss: 1.209\n",
      "[Epoch 7, Batch 600] loss: 1.177\n",
      "[Epoch 7, Batch 700] loss: 1.210\n",
      "[Epoch 7, Batch 800] loss: 1.138\n",
      "[Epoch 7, Batch 900] loss: 1.132\n",
      "[Epoch 7, Batch 1000] loss: 1.102\n",
      "[Epoch 7, Batch 1100] loss: 1.150\n",
      "[Epoch 7, Batch 1200] loss: 1.105\n",
      "[Epoch 7, Batch 1300] loss: 1.119\n",
      "[Epoch 7, Batch 1400] loss: 1.107\n",
      "[Epoch 7, Batch 1500] loss: 1.079\n",
      "[Epoch 8, Batch 100] loss: 1.046\n",
      "[Epoch 8, Batch 200] loss: 1.082\n",
      "[Epoch 8, Batch 300] loss: 1.058\n",
      "[Epoch 8, Batch 400] loss: 1.038\n",
      "[Epoch 8, Batch 500] loss: 1.032\n",
      "[Epoch 8, Batch 600] loss: 1.050\n",
      "[Epoch 8, Batch 700] loss: 1.040\n",
      "[Epoch 8, Batch 800] loss: 0.989\n",
      "[Epoch 8, Batch 900] loss: 1.003\n",
      "[Epoch 8, Batch 1000] loss: 0.936\n",
      "[Epoch 8, Batch 1100] loss: 0.980\n",
      "[Epoch 8, Batch 1200] loss: 0.960\n",
      "[Epoch 8, Batch 1300] loss: 0.962\n",
      "[Epoch 8, Batch 1400] loss: 0.928\n",
      "[Epoch 8, Batch 1500] loss: 0.920\n",
      "[Epoch 9, Batch 100] loss: 0.899\n",
      "[Epoch 9, Batch 200] loss: 0.936\n",
      "[Epoch 9, Batch 300] loss: 0.932\n",
      "[Epoch 9, Batch 400] loss: 0.914\n",
      "[Epoch 9, Batch 500] loss: 0.883\n",
      "[Epoch 9, Batch 600] loss: 0.912\n",
      "[Epoch 9, Batch 700] loss: 0.892\n",
      "[Epoch 9, Batch 800] loss: 0.868\n",
      "[Epoch 9, Batch 900] loss: 0.856\n",
      "[Epoch 9, Batch 1000] loss: 0.828\n",
      "[Epoch 9, Batch 1100] loss: 0.881\n",
      "[Epoch 9, Batch 1200] loss: 0.860\n",
      "[Epoch 9, Batch 1300] loss: 0.866\n",
      "[Epoch 9, Batch 1400] loss: 0.821\n",
      "[Epoch 9, Batch 1500] loss: 0.801\n",
      "[Epoch 10, Batch 100] loss: 0.770\n",
      "[Epoch 10, Batch 200] loss: 0.834\n",
      "[Epoch 10, Batch 300] loss: 0.814\n",
      "[Epoch 10, Batch 400] loss: 0.814\n",
      "[Epoch 10, Batch 500] loss: 0.784\n",
      "[Epoch 10, Batch 600] loss: 0.793\n",
      "[Epoch 10, Batch 700] loss: 0.784\n",
      "[Epoch 10, Batch 800] loss: 0.758\n",
      "[Epoch 10, Batch 900] loss: 0.754\n",
      "[Epoch 10, Batch 1000] loss: 0.728\n",
      "[Epoch 10, Batch 1100] loss: 0.773\n",
      "[Epoch 10, Batch 1200] loss: 0.763\n",
      "[Epoch 10, Batch 1300] loss: 0.740\n",
      "[Epoch 10, Batch 1400] loss: 0.708\n",
      "[Epoch 10, Batch 1500] loss: 0.706\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    model.train()  # Set model to training mode\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        # inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:  # Print every 100 mini-batches\n",
    "            print(f\"[Epoch {epoch + 1}, Batch {i + 1}] loss: {running_loss / 100:.3f}\")\n",
    "            running_loss = 0.0\n",
    "\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing Test on the test data\n",
    "def test_model(model, test_loader, criterion, device=\"cpu\"):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for inputs, targets in test_loader:\n",
    "            # inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss += loss.item() * inputs.size(0)  # Accumulate test loss\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "\n",
    "    avg_test_loss = test_loss / total\n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    print(f\"Test Loss: {avg_test_loss:.4f}, Test Accuracy: {accuracy:.2f}%\")\n",
    "    return avg_test_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.7965, Test Accuracy: 73.12%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = test_model(model, test_loader, criterion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
