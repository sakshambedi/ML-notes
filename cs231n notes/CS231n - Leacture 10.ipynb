{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "169542c9",
      "metadata": {},
      "source": [
        "# Neural Networks: Data Preprocessing, Initialization, and Regularization\n",
        "This notebook covers the following topics:\n",
        "- Data Preprocessing\n",
        "- Weight Initialization\n",
        "- Batch Normalization\n",
        "- Regularization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2e06a06",
      "metadata": {},
      "source": [
        "## Data Preprocessing\n",
        "### Mean Subtraction\n",
        "Mean subtraction is the process of subtracting the mean of each feature from the dataset, ensuring that each feature has a mean of zero. This is often done to center the data.\n",
        "```python\n",
        "X -= np.mean(X, axis=0)\n",
        "```\n",
        "\n",
        "### Normalization\n",
        "Normalization scales the features so that they have a standard deviation of one.\n",
        "```python\n",
        "X /= np.std(X, axis=0)\n",
        "```\n",
        "\n",
        "### PCA and Whitening\n",
        "PCA (Principal Component Analysis) projects data to a lower-dimensional space. Whitening further decorrelates the data and scales it to have unit variance.\n",
        "\n",
        "\n",
        "```python\n",
        "X -= np.mean(X, axis=0)\n",
        "cov = np.dot(X.T, X) / X.shape[0]\n",
        "U, S, V = np.linalg.svd(cov)\n",
        "Xrot = np.dot(X, U)\n",
        "Xwhite = Xrot / np.sqrt(S + 1e-5)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "659ab6ca",
      "metadata": {},
      "source": [
        "## Weight Initialization\n",
        "### Small Random Numbers\n",
        "Initialize weights with small random values to break symmetry and allow the network to learn.\n",
        "```python\n",
        "W = 0.01 * np.random.randn(D, H)\n",
        "```\n",
        "\n",
        "### Variance Scaling\n",
        "Scale the weights by the inverse square root of the number of input units to maintain a consistent variance.\n",
        "```python\n",
        "W = np.random.randn(D, H) / np.sqrt(D)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db857d08",
      "metadata": {},
      "source": [
        "## Batch Normalization\n",
        "Batch normalization normalizes the inputs of each layer to have zero mean and unit variance.\n",
        "```python\n",
        "def batchnorm_forward(x, gamma, beta, eps=1e-5):\n",
        "    N, D = x.shape\n",
        "    mu = np.mean(x, axis=0)\n",
        "    var = np.var(x, axis=0)\n",
        "    x_normalized = (x - mu) / np.sqrt(var + eps)\n",
        "    out = gamma * x_normalized + beta\n",
        "    cache = (x, mu, var, x_normalized, gamma, beta, eps)\n",
        "    return out, cache\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "897d05a5",
      "metadata": {},
      "source": [
        "## Regularization\n",
        "### L2 Regularization\n",
        "L2 regularization adds a penalty equal to the sum of the squared weights to the loss function.\n",
        "```python\n",
        "loss += 0.5 * reg * np.sum(W * W)\n",
        "```\n",
        "\n",
        "### L1 Regularization\n",
        "L1 regularization adds a penalty equal to the sum of the absolute values of the weights to the loss function.\n",
        "```python\n",
        "loss += reg * np.sum(np.abs(W))\n",
        "```\n",
        "\n",
        "### Dropout\n",
        "Dropout randomly sets a fraction of the input units to zero at each update during training time, which helps prevent overfitting.\n",
        "```python\n",
        "def dropout_forward(x, p=0.5, train=True):\n",
        "    if train:\n",
        "        mask = (np.random.rand(*x.shape) < p) / p\n",
        "        out = x * mask\n",
        "    else:\n",
        "        out = x\n",
        "    return out\n",
        "```\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
