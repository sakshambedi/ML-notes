{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Artificial Neural Network (ANN)\n",
    "\n",
    "**_NOTE_:** After reading online and recommended by friends. PyTorch seems to be a better lib. The code in the book is tensorflow but I'll try my best to convert it into pyTorch code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Biological to Artificial Neurons\n",
    "\n",
    "Surprisingly, ANNs have been around for quite a while: they were first introduced back in 1943 by the neurophysiologist Warren McCulloch and the mathematician Walter Pitts. In their landmark paper,2 “[A Logical Calculus of Ideas Immanent in Nervous Activity](https://scholar.google.com/scholar?q=A+Logical+Calculus+of+Ideas+Immanent+in+Nervous+Activity+author%3Amcculloch),” McCulloch and Pitts presented a simplified computational model of how biological neurons might work together in animal brains to perform complex computations using propositional logic. This was the first artificial neural network architecture. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biological Neural\n",
    "\n",
    "A biological neuron, primarily found in animal brains, consists of a cell body with a nucleus, branching extensions called dendrites, and a long extension called the axon. The axon's length can vary greatly and ends in branches called telodendria, which have synaptic terminals at their tips. These terminals connect to the dendrites or cell bodies of other neurons. Neurons receive electrical impulses (signals) via synapses. When enough signals are received within a short time, the neuron fires its own signals.\n",
    "\n",
    "![Biological Neuron](<./img/chapter 10/Screenshot 2024-06-07 at 5.46.05 PM.jpg>)\n",
    "\n",
    "### The Perceptron\n",
    "The Perceptron is one of the simplest ANN architectures, invented in 1957 by Frank Rosenblatt. It is based on a slightly different artificial neuron (see Figure 10-4) called a _threshold logic unit (TLU)_ , or sometimes a linear threshold unit (LTU): the inputs and output are now numbers (instead of binary on/off values) and each input con‐ nection is associated with a weight. The TLU computes a weighted sum of its inputs ($z = w_1 x_1 + w_2 x_2 + ⋯ + w_n x_n = x^T w$), then applies a step function to that sum and outputs the result: $h_{w}(\\mathbf{x}) = \\text{step}(z), \\text{where} \\; \\mathbf{z} = \\mathbf{x}^T \\mathbf{w}$.\n",
    "\n",
    "![Threshold Logic Unit](<./img/chapter 10/Screenshot 2024-06-07 at 5.50.52 PM.jpg>)\n",
    "\n",
    "The most common step function used in Perceptrons is the Heaviside step function\n",
    "\n",
    "$$\n",
    "\\text{Equation 10.1 : Common Step Functions used in Perceptron} \\\\ \\\\ \n",
    "\n",
    "\\text{heaviside}(z) = \n",
    "\\begin{cases} \n",
    "0 & \\text{if } z < 0 \\\\\n",
    "1 & \\text{if } z \\geq 0 \n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{sgn}(z) = \n",
    "\\begin{cases} \n",
    "-1 & \\text{if } z < 0 \\\\\n",
    "0 & \\text{if } z = 0 \\\\\n",
    "+1 & \\text{if } z > 0 \n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "A Perceptron is simply composed of a single layer of TLUs, with each TLU connected to all the inputs. When all the neurons in a layer are connected to every neuron in the previous layer (i.e., its input neurons), it is called a fully connected layer or a dense layer. \n",
    "\n",
    "In 1949, Donald Hebb suggested that when a biological neuron frequently triggers another neuron, the connection between them strengthens. This concept, summarized by Siegrid Löwel as \"Cells that fire together, wire together,\" is known as Hebb's rule (or Hebbian learning). According to this rule, the connection weight between two neurons increases when they have the same output.\n",
    "\n",
    "Perceptrons are trained using a variant of this rule that considers the network's error, reinforcing connections that reduce the error. Specifically, the Perceptron processes one training instance at a time and makes predictions. For every output neuron that makes an incorrect prediction, it reinforces the connection weights from the inputs that would have led to the correct prediction.\n",
    "\n",
    "$$\n",
    "w_{i,j}^{(\\text{next step})} = w_{i,j} + \\eta (y_j - \\hat{y}_j) x_i\n",
    "$$\n",
    "\n",
    "- $ w_{i,j} $ is the connection weight between the $ i $-th input neuron and the $ j $-th output neuron.\n",
    "- $ x_i $ is the $ i $-th input value of the current training instance.\n",
    "- $ \\hat{y}_j $ is the output of the $ j $-th output neuron for the current training instance.\n",
    "- $ y_j $ is the target output of the $ j $-th output neuron for the current training instance.\n",
    "- $ \\eta $ is the learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Layer Perceptron and Back Propagation\n",
    "\n",
    "An MLP is composed of one (passthrough) input layer, one or more layers of TLUs, called hidden layers, and one final layer of TLUs called the output layer (see Figure 10-7). The layers close to the input layer are usually called the lower layers, and the ones close to the outputs are usually called the upper layers. Every layer except the output layer includes a bias neuron and is fully connected to the next layer.\n",
    "\n",
    "![Multi-Layer Perceptron](<./img/chapter 10/Screenshot 2024-06-07 at 6.17.40 PM.jpg>)\n",
    "\n",
    "When an artificial neural network (ANN) has many hidden layers, it is called a deep neural network (DNN). Deep Learning is the study of DNNs and models with deep stacks of computations. However, many people refer to Deep Learning whenever neural networks are mentioned, even if they are shallow.\n",
    "\n",
    "But in 1986, David Rumelhart, Geoffrey Hinton and Ronald Williams published a [groundbreaking paper](https://scholar.google.com/scholar?q=Learning+Internal+Representations+by+Error+Propagation+author%3Arumelhart) introducing the backpropagation training algorithm, which is still used today. In short, it is simply Gradient Descent using an efficient technique for computing the gradients automatically: in just two passes through the network (one forward, one backward), the backpropagation algorithm is able to compute the gradient of the network’s error with regards to every single model parameter. In other words, it can find out how each connection weight and each bias term should be tweaked in order to reduce the error. Once it has these gradients, it just performs a regular Gradient Descent step, and the whole process is repeated until the network converges to the solution.\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{Equation : Computing the } & \\text{outputs of a fully connected layer.} \\\\ \n",
    "h_{W,b}(\\mathbf{X}) & = \\phi(\\mathbf{XW} + \\mathbf{b}) \n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "- **Input Matrix ($\\mathbf{X}$)**: Represents the matrix of input features. Each row corresponds to an instance, and each column corresponds to a feature.\n",
    "- **Weight Matrix ($\\mathbf{W}$)**: Contains all the connection weights except for the ones from the bias neuron. It has one row per input neuron and one column per artificial neuron in the layer.\n",
    "- **Bias Vector ($\\mathbf{b}$)**: Contains all the connection weights between the bias neuron and the artificial neurons. It has one bias term per artificial neuron.\n",
    "- **Activation Function ($\\phi$)**: Called the activation function. When the artificial neurons are Threshold Logic Units (TLUs), it is a step function. Other activation functions will be discussed shortly.\n",
    "\n",
    "For each training instance the backpropagation algorithm first makes a prediction (forward pass), measures the error, then goes through each layer in reverse to measure the error con‐ tribution from each connection (reverse pass), and finally slightly tweaks the connection weights to reduce the error (Gradient Descent step)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[another resource\n",
    "](https://www.youtube.com/watch?v=SmZmBKc7Lrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context and Problem\n",
    "\n",
    "In machine learning, especially in neural networks, an activation function is used to introduce non-linearity into the model. This non-linearity is crucial because it allows the network to learn and model more complex patterns in the data.\n",
    "\n",
    "### Original Setup\n",
    "\n",
    "Initially, the Multilayer Perceptron (MLP) architecture used a step function as the activation function. The step function is binary—it outputs one value if the input is above a certain threshold and another value if it's below.\n",
    "\n",
    "### Issue with the Step Function\n",
    "\n",
    "The problem with the step function is that it only outputs flat segments (either 0 or 1). This creates a significant issue during training with Gradient Descent, a common optimization algorithm. Gradient Descent relies on gradients (derivatives) to update the model's parameters. However, the step function doesn't have a gradient (its derivative is zero everywhere except at the threshold), meaning Gradient Descent can't effectively update the weights, as it has no slope to follow.\n",
    "\n",
    "### Solution: Logistic Function\n",
    "\n",
    "To address this, the authors replaced the step function with the logistic function, also known as the sigmoid function. The logistic function is defined as:\n",
    "\n",
    "$$\n",
    "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
    "$$\n",
    "\n",
    "The logistic function has a smooth, S-shaped curve that outputs values between 0 and 1. Unlike the step function, the logistic function has a well-defined, non-zero derivative everywhere. This smooth gradient allows Gradient Descent to make progress at every step, enabling the model to learn more effectively.\n",
    "\n",
    "### Importance of Non-zero Derivative\n",
    "\n",
    "The logistic function’s non-zero derivative means that small changes in the input (weights) produce small changes in the output, which is crucial for the Gradient Descent algorithm to find the minimum of the loss function. This enables the neural network to adjust its weights in small increments, improving its accuracy over time.\n",
    "\n",
    "### Broader Implications\n",
    "\n",
    "This improvement isn’t limited to just the logistic function. The backpropagation algorithm, which is used to train neural networks, works well with many other activation functions that have non-zero derivatives. These include:\n",
    "\n",
    "- **Tanh (Hyperbolic Tangent)**: Similar to the logistic function but outputs values between -1 and 1, which tends to make each layer’s output more or less centered around 0 at the beginning of training. This often helps speed up convergence. $$\\begin{align*} tanh(z) = 2\\sigma(2z) -1 \\end{align*}$$ \n",
    "- **ReLU (Rectified Linear Unit)**: It is continuous but unfortunately not differentiable at z = 0 (the slope changes abruptly, which can make Gradient Descent bounce around), and its derivative is 0 for z < 0. Outputs the input directly if it’s positive; otherwise, it outputs zero. It has become very popular due to its simplicity and effectiveness. $$\\begin{align*} ReLU(z) = max(0,z) \\end{align*}$$\n",
    "\n",
    "These popular activation functions and their derivatives are represented in Figure 10-8. \n",
    "\n",
    "![Activation Functions and their Derivatives](<./img/chapter 10/Screenshot 2024-06-09 at 4.35.43 PM.jpg>)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression MLPs\n",
    "\n",
    "Multilayer Perceptrons (MLPs) can be effectively used for regression tasks, predicting continuous values such as house prices with a single output neuron. For predicting multiple values, like the 2D coordinates of an object's center, multiple output neurons are used, with one neuron per value. For instance, predicting both the coordinates and the bounding box of an object requires four output neurons. Generally, no activation function is used for output neurons in regression, allowing any range of values. However, if outputs need to be positive, the ReLU or softplus functions can be used, and for outputs within a specific range, the logistic or hyperbolic tangent functions are suitable. The mean squared error (MSE) is the typical loss function for training, but for datasets with many outliers, mean absolute error (MAE) or the Huber loss, which combines MSE and MAE, may be preferred.\n",
    "\n",
    "\n",
    "| Hyperparameter            | Typical Value                                                                         |\n",
    "|:---------------------------|---------------------------------------------------------------------------------------|\n",
    "| \\# input neurons           | One per input feature (e.g., $28 \\times 28 = 784$ for MNIST)                                 |\n",
    "| \\# hidden layers           | Depends on the problem. Typically 1 to 5.                                             |\n",
    "| \\# neurons per hidden layer| Depends on the problem. Typically 10 to 100.                                          |\n",
    "| \\# output neurons          | 1 per prediction dimension                                                           |\n",
    "| Hidden activation         | ReLU (or SELU)                                                        |\n",
    "| Output activation         | None or ReLU/Softplus (if positive outputs) or Logistic/Tanh (if bounded outputs)    |\n",
    "| Loss function             | MSE or MAE/Huber (if outliers)                                                       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification MLPs\n",
    "\n",
    "MLPs can also be used for classification tasks. For a binary classification problem, you just need a single output neuron using the logistic activation function: the output will be a number between 0 and 1, which you can interpret as the estimated probabil‐ ity of the positive class.\n",
    "\n",
    "Multilayer Perceptrons (MLPs) are well-suited for handling multilabel binary classification tasks. For instance, in an email classification system, an MLP can predict both whether an email is spam or ham and whether it is urgent or non-urgent. This requires two output neurons, each using the logistic activation function. The first neuron outputs the probability that the email is spam, and the second outputs the probability that it is urgent. Each positive class (spam, urgent) gets a dedicated output neuron. The output probabilities do not need to sum to one, allowing for various combinations of labels such as non-urgent ham, urgent ham, non-urgent spam, and urgent spam.\n",
    "\n",
    "If each instance can belong only to a single class, out of 3 or more possible classes (e.g., classes 0 through 9 for digit image classification), then you need to have one output neuron per class, and you should use the softmax activation function for the whole output layer (see Figure 10-9). The softmax function (introduced in Chapter 4) will ensure that all the estimated probabilities are between 0 and 1 and that they add up to one (which is required if the classes are exclusive). This is called multiclass clas‐ sification.\n",
    "\n",
    "![A Modern MLP (including ReLU and softmax) ](<./img/chapter 10/Screenshot 2024-06-09 at 5.51.55 PM.jpg>)\n",
    "\n",
    "Regarding the loss function, since we are predicting probability distributions, the cross-entropy (also called the log loss, see Chapter 4) is generally a good choice.\n",
    "\n",
    "Table 10-2 : Typical Classification MLP Archtecture\n",
    "\n",
    "| Hyperparameter              | Binary Classification      | Multilabel Binary Classification | Multiclass Classification      |\n",
    "|-----------------------------|----------------------------|----------------------------------|-------------------------------|\n",
    "| Input and hidden layers     | Same as regression         | Same as regression               | Same as regression            |\n",
    "| # output neurons            | 1                          | 1 per label                      | 1 per class                   |\n",
    "| Output layer activation     | Logistic                   | Logistic                         | Softmax                       |\n",
    "| Loss function               | Cross-Entropy              | Cross-Entropy                    | Cross-Entropy                 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libs\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transformer to normlize this data\n",
    "# Convert the input to tensors and noramlize it\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Normalization and Why is It Helpful?\n",
    "Normalizing a set of data transforms the set of data to be on a similar scale. For machine learning models, our goal is usually to recenter and rescale our data such that is between 0 and 1 or -1 and 1, depending on the data itself. One common way to accomplish this is to calculate the mean and the standard deviation on the set of data and transform each sample by subtracting the mean and dividing by the standard deviation, which is good if we assume that the data follows a normal distribution as this method helps us standardize the data and achieve a standard normal distribution.\n",
    "\n",
    "Normalization can help training of our neural networks as the different features are on a similar scale, which helps to stabilize the gradient descent step, allowing us to use larger learning rates or help models converge faster for a given learning rate.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60000, 28, 28]), torch.Size([10000, 28, 28]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the data and load the dataset\n",
    "# In my case the datasets are already downloaded so download=False\n",
    "training_data = datasets.FashionMNIST(\n",
    "    \"./datasets/FashionMNIST\", train=True, download=False, transform=transform\n",
    ")\n",
    "\n",
    "testing_data = datasets.FashionMNIST(\n",
    "    \"./datasets/FashionMNIST\", train=False, download=False, transform=transform\n",
    ")\n",
    "\n",
    "\n",
    "# index_to_class = {i:s for i,s in enumerate(training_data.classes)}\n",
    "training_data.data.shape, testing_data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((torch.uint8, torch.Size([60000, 28, 28])),\n",
       " (torch.uint8, torch.Size([10000, 28, 28])))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    (training_data.data.dtype, training_data.data.shape),\n",
    "    (testing_data.data.dtype, testing_data.data.shape),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the datasets for training and validation\n",
    "train_size = 55000  # int(0.8 * len(training_data))\n",
    "validation_size = 5000  # int(0.2 * len(training_data))\n",
    "\n",
    "train_dataset, validation_dataset = random_split(\n",
    "    training_data, lengths=[train_size, validation_size]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x112ba50a0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x112b8be30>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x112b8bdd0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating dataloaders\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    prefetch_factor=2,\n",
    ")  # num_workers for efficient utilize CPU cores and  Memory\n",
    "val_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(testing_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T-shirt/top',\n",
       " 'Trouser',\n",
       " 'Pullover',\n",
       " 'Dress',\n",
       " 'Coat',\n",
       " 'Sandal',\n",
       " 'Shirt',\n",
       " 'Sneaker',\n",
       " 'Bag',\n",
       " 'Ankle boot']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_name = training_data.classes\n",
    "classes_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting devices for MPS support, incase of the M1 macbook. This may differ depending upon the computer\n",
    "device = (\n",
    "    torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    ")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "    \n",
    "class FashionMNISTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FashionMNISTModel, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(28 * 28, 300)\n",
    "        self.fc2 = nn.Linear(300, 100)\n",
    "        self.fc3 = nn.Linear(100, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Summarizing models for Pytorch\n",
    "from collections import OrderedDict\n",
    "\n",
    "def model_summary(model, input_size):\n",
    "    def register_hook(module):\n",
    "        def hook(module, input, output):\n",
    "            class_name = str(module.__class__).split(\".\")[-1].split(\"'\")[0]\n",
    "            module_idx = len(summary)\n",
    "            m_key = \"%s-%i\" % (class_name, module_idx + 1)\n",
    "            summary[m_key] = OrderedDict()\n",
    "            summary[m_key][\"input_shape\"] = list(input[0].size())\n",
    "            summary[m_key][\"input_shape\"][0] = batch_size\n",
    "            if isinstance(output, (list, tuple)):\n",
    "                summary[m_key][\"output_shape\"] = [\n",
    "                    [-1] + list(o.size())[1:] for o in output\n",
    "                ]\n",
    "            else:\n",
    "                summary[m_key][\"output_shape\"] = list(output.size())\n",
    "                summary[m_key][\"output_shape\"][0] = batch_size\n",
    "            params = 0\n",
    "            if hasattr(module, \"weight\") and hasattr(module.weight, \"size\"):\n",
    "                params += torch.prod(torch.LongTensor(list(module.weight.size())))\n",
    "                summary[m_key][\"trainable\"] = module.weight.requires_grad\n",
    "            if hasattr(module, \"bias\") and hasattr(module.bias, \"size\"):\n",
    "                params += torch.prod(torch.LongTensor(list(module.bias.size())))\n",
    "            summary[m_key][\"nb_params\"] = params\n",
    "\n",
    "        if (\n",
    "            not isinstance(module, nn.Sequential)\n",
    "            and not isinstance(module, nn.ModuleList)\n",
    "            and not (module == model)\n",
    "        ):\n",
    "            hooks.append(module.register_forward_hook(hook))\n",
    "\n",
    "    device = (\n",
    "        torch.device(\"mps\")\n",
    "        if torch.backends.mps.is_available()\n",
    "        else torch.device(\"cpu\")\n",
    "    )\n",
    "    model.to(device)\n",
    "\n",
    "    summary = OrderedDict()\n",
    "    hooks = []\n",
    "    model.apply(register_hook)\n",
    "\n",
    "    x = torch.zeros((1, *input_size)).to(device)\n",
    "    model(x)\n",
    "\n",
    "    for h in hooks:\n",
    "        h.remove()\n",
    "\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "    print(\"{:>20}  {:>25} {:>15}\".format(\"Layer (type)\", \"Output Shape\", \"Param #\"))\n",
    "    print(\"================================================================\")\n",
    "    total_params = 0\n",
    "    total_output = 0\n",
    "    trainable_params = 0\n",
    "    for layer in summary:\n",
    "        line_new = \"{:>20}  {:>25} {:>15}\".format(\n",
    "            layer,\n",
    "            str(summary[layer][\"output_shape\"]),\n",
    "            \"{0:,}\".format(summary[layer][\"nb_params\"]),\n",
    "        )\n",
    "        total_params += summary[layer][\"nb_params\"]\n",
    "        total_output += torch.prod(torch.LongTensor(summary[layer][\"output_shape\"]))\n",
    "        if \"trainable\" in summary[layer]:\n",
    "            if summary[layer][\"trainable\"]:\n",
    "                trainable_params += summary[layer][\"nb_params\"]\n",
    "        print(line_new)\n",
    "\n",
    "    total_input_size = abs(torch.prod(torch.LongTensor(input_size)) * batch_size)\n",
    "    total_output_size = abs(total_output * 4.0)  # x4 for float32\n",
    "    total_params_size = abs(total_params * 4.0)  # x4 for float32\n",
    "    total_size = total_params_size + total_output_size + total_input_size\n",
    "\n",
    "    print(\"================================================================\")\n",
    "    print(\"Total params: {0:,}\".format(total_params))\n",
    "    print(\"Trainable params: {0:,}\".format(trainable_params))\n",
    "    print(\"Non-trainable params: {0:,}\".format(total_params - trainable_params))\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "    print(\"Input size (MB): %0.2f\" % (total_input_size / (1024**2.0)))\n",
    "    print(\"Forward/backward pass size (MB): %0.2f\" % (total_output_size / (1024**2.0)))\n",
    "    print(\"Params size (MB): %0.2f\" % (total_params_size / (1024**2.0)))\n",
    "    print(\"Estimated Total Size (MB): %0.2f\" % (total_size / (1024**2.0)))\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation for the code line by line\n",
    "\n",
    "1. FashionMNISTModel is a subclass of nn.Module, which is the base class for all neural network modules in PyTorch.\n",
    "2. This is a sequential model. It is  just composed of a single stack of layers, connected sequentially.\n",
    "3. Suppose you have a batch of images with the shape [batch_size, channels, height, width] (e.g., [64, 1, 28, 28] for a batch of 64 grayscale 28x28 images). After applying nn.Flatten(), the shape becomes [batch_size,  channels * height * width] (e.g., [64, 784] for the previous example). This transformation flattens each image into a vector of size 784 while preserving the batch dimension. \n",
    "4. Next we add a hidden layer with 300 neurons. It will use the ReLU activa‐ tion function. Each Dense layer manages its own weight matrix, containing all the connection weights between the neurons and their inputs. It also manages a vector of bias terms (one per neuron).\n",
    "5. Next we add a second hidden layer with 100 neurons, also using the ReLU activation function.\n",
    "6. Finally, we add a output layer with 10 neurons (one per class), using the softmax activation function (because the classes are exclusive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "           Flatten-1                  [64, 784]               0\n",
      "            Linear-2                  [64, 300]         235,500\n",
      "            Linear-3                  [64, 100]          30,100\n",
      "            Linear-4                   [64, 10]           1,010\n",
      "================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 0.29\n",
      "Params size (MB): 1.02\n",
      "Estimated Total Size (MB): 1.36\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Making a FashionMNISTModel object and running it on the MPS.\n",
    "model = FashionMNISTModel().to(device=device)\n",
    "\n",
    "# Print the model summary\n",
    "model_summary(model, (1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Name: , Layer Type: FashionMNISTModel\n",
      "Layer Name: flatten, Layer Type: Flatten\n",
      "Layer Name: fc1, Layer Type: Linear\n",
      "Layer Name: fc2, Layer Type: Linear\n",
      "Layer Name: fc3, Layer Type: Linear\n"
     ]
    }
   ],
   "source": [
    "for name, module in model.named_modules():\n",
    "    print(f\"Layer Name: {name}, Layer Type: {module.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 2.1600, Accuracy: 31.74%\n",
      "Epoch [2/50], Loss: 1.6604, Accuracy: 52.23%\n",
      "Epoch [3/50], Loss: 1.1916, Accuracy: 66.70%\n",
      "Epoch [4/50], Loss: 0.9493, Accuracy: 71.42%\n",
      "Epoch [5/50], Loss: 0.8215, Accuracy: 73.18%\n",
      "Epoch [6/50], Loss: 0.7479, Accuracy: 74.11%\n",
      "Epoch [7/50], Loss: 0.7013, Accuracy: 74.98%\n",
      "Epoch [8/50], Loss: 0.6687, Accuracy: 75.76%\n",
      "Epoch [9/50], Loss: 0.6438, Accuracy: 76.61%\n",
      "Epoch [10/50], Loss: 0.6233, Accuracy: 77.19%\n",
      "Epoch [11/50], Loss: 0.6060, Accuracy: 77.88%\n",
      "Epoch [12/50], Loss: 0.5908, Accuracy: 78.58%\n",
      "Epoch [13/50], Loss: 0.5773, Accuracy: 79.08%\n",
      "Epoch [14/50], Loss: 0.5648, Accuracy: 79.60%\n",
      "Epoch [15/50], Loss: 0.5536, Accuracy: 80.05%\n",
      "Epoch [16/50], Loss: 0.5434, Accuracy: 80.49%\n",
      "Epoch [17/50], Loss: 0.5342, Accuracy: 80.89%\n",
      "Epoch [18/50], Loss: 0.5257, Accuracy: 81.23%\n",
      "Epoch [19/50], Loss: 0.5181, Accuracy: 81.59%\n",
      "Epoch [20/50], Loss: 0.5109, Accuracy: 81.84%\n",
      "Epoch [21/50], Loss: 0.5044, Accuracy: 82.12%\n",
      "Epoch [22/50], Loss: 0.4985, Accuracy: 82.33%\n",
      "Epoch [23/50], Loss: 0.4930, Accuracy: 82.45%\n",
      "Epoch [24/50], Loss: 0.4878, Accuracy: 82.69%\n",
      "Epoch [25/50], Loss: 0.4831, Accuracy: 82.88%\n",
      "Epoch [26/50], Loss: 0.4787, Accuracy: 83.08%\n",
      "Epoch [27/50], Loss: 0.4744, Accuracy: 83.21%\n",
      "Epoch [28/50], Loss: 0.4704, Accuracy: 83.36%\n",
      "Epoch [29/50], Loss: 0.4666, Accuracy: 83.45%\n",
      "Epoch [30/50], Loss: 0.4632, Accuracy: 83.66%\n",
      "Epoch [31/50], Loss: 0.4599, Accuracy: 83.79%\n",
      "Epoch [32/50], Loss: 0.4566, Accuracy: 83.88%\n",
      "Epoch [33/50], Loss: 0.4537, Accuracy: 83.96%\n",
      "Epoch [34/50], Loss: 0.4509, Accuracy: 84.02%\n",
      "Epoch [35/50], Loss: 0.4479, Accuracy: 84.08%\n",
      "Epoch [36/50], Loss: 0.4452, Accuracy: 84.23%\n",
      "Epoch [37/50], Loss: 0.4425, Accuracy: 84.33%\n",
      "Epoch [38/50], Loss: 0.4400, Accuracy: 84.40%\n",
      "Epoch [39/50], Loss: 0.4377, Accuracy: 84.46%\n",
      "Epoch [40/50], Loss: 0.4353, Accuracy: 84.59%\n",
      "Epoch [41/50], Loss: 0.4331, Accuracy: 84.68%\n",
      "Epoch [42/50], Loss: 0.4309, Accuracy: 84.72%\n",
      "Epoch [43/50], Loss: 0.4288, Accuracy: 84.76%\n",
      "Epoch [44/50], Loss: 0.4267, Accuracy: 84.87%\n",
      "Epoch [45/50], Loss: 0.4248, Accuracy: 84.91%\n",
      "Epoch [46/50], Loss: 0.4228, Accuracy: 85.03%\n",
      "Epoch [47/50], Loss: 0.4208, Accuracy: 85.05%\n",
      "Epoch [48/50], Loss: 0.4189, Accuracy: 85.16%\n",
      "Epoch [49/50], Loss: 0.4171, Accuracy: 85.25%\n",
      "Epoch [50/50], Loss: 0.4155, Accuracy: 85.29%\n",
      "Training complete\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Model is set to training mode\n",
    "    model.train()\n",
    "    \n",
    "    # Initializes new values at each epoch\n",
    "    running_loss= 0.0\n",
    "    correct, total = 0,0\n",
    "    \n",
    "    \n",
    "    # Batch Loop\n",
    "    for data, target in train_loader:\n",
    "        \n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(data)\n",
    "        loss = loss_fn(outputs, target) # This is calculating the loss from the outputs from the forward pass and the real output in the data set\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward() # Calculate the gardient of the loss with respect to model parameter\n",
    "        optimizer.step() # Updates the model parameters using the gradients computed during the backward pass   \n",
    "        \n",
    "        \n",
    "        # Accumulates the loss for the current batch\n",
    "        running_loss += loss.item() * data.size(0)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "    \n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader.dataset) # Epoch loss calculates the average loss over the dataset\n",
    "    accuracy = 100 * correct / total # accuracy is the % accuracy of the model.\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "print(\"Training complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explation of the code \n",
    "\n",
    "\n",
    "1. Setting the number of the times the entire dataset will pass through the network  \n",
    "2. Training the Model. The model.train() call sets the model to training mode, enabling features like dropout and batch normalization.\n",
    "3. Initialize each varibable to track loss and accuracy\n",
    "4. Batch Loop : Iterates through batches of data. train_loader provides batches of images and their corresponding labels. Each batch is moved to the appropriate device (CPU or MPS).\n",
    "5. Zero Gradients \n",
    "6. Performing a forward pass and calculate the loss. The funtion uses CrossEntropyLoss which is a combination of LogSoftmax and NLLLoss\n",
    "7. Perform back propagation and update the model parameters using the gradients calculated.\n",
    "8. Track the loss over the batch.\n",
    "9. Calculate accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test images: 85.34%\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Testing the model of validation data\n",
    "    for data, target in val_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        outputs = model(data)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "\n",
    "print(f'Accuracy of the model on the test images: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the model turns out to be $85.74\\%$. \n",
    "\n",
    "\n",
    "If there is a accuracy delta between training dataset and the validation dataset , it is a sign that the model is overfitting over the training data. Overfitting occurs when a model learns the training data too well, including the noise and details that do not generalize to new data. This typically results in excellent performance on the training data but poor performance on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.4524, Test Accuracy: 83.99%\n"
     ]
    }
   ],
   "source": [
    "# Testing phase\n",
    "model.eval()  # Set model to evaluation mode\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        outputs = model(data)\n",
    "        loss = loss_fn(outputs, target)\n",
    "        test_loss += loss.item() * data.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Regression MLP \n",
    "\n",
    "We will be using the California Housing dataset. \n",
    "\n",
    "Credits to this resource  : [Building a Regression Model for California Housing Dataset using MyTorch](https://machinelearningmastery.com/building-a-regression-model-in-pytorch/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Fetching the dataset\n",
    "data = fetch_california_housing()\n",
    "X,y = data.data, data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardizing data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_raw)\n",
    "X_train = scaler.transform(X_train_raw)\n",
    "X_test = scaler.transform(X_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the training datasets\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test= torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Define the model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(8, 24),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(24, 12),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(12, 6),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(6, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "n_epochs = 100   # number of epochs to run\n",
    "batch_size = 10  # size of each batch\n",
    "batch_start = torch.arange(0, len(X_train), batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the loss function and the optimizer\n",
    "\n",
    "loss_fn = nn.MSELoss()  # mean square error\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.30\n",
      "RMSE: 0.55\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Hold the best model\n",
    "best_mse = np.inf   # init to infinity\n",
    "best_weights = None\n",
    "history = []\n",
    "\n",
    "\n",
    "# training Loop\n",
    "for epoch in range(n_epochs):\n",
    "    # set the model on training mode\n",
    "    model.train()\n",
    "    with tqdm.tqdm(batch_start, unit=\"batch\", mininterval=0, disable=True) as bar:\n",
    "        bar.set_description(f\"Epoch : [{epoch}/{n_epochs}]\")\n",
    "        for start in bar:\n",
    "            # Take a batch\n",
    "            X_batch = X_train[start:start+batch_size]\n",
    "            y_batch = y_train[start:start+batch_size]\n",
    "            \n",
    "            # forward pass\n",
    "            y_pred = model(X_batch) \n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            \n",
    "            #backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            \n",
    "            #update Weights\n",
    "            optimizer.step()\n",
    "            \n",
    "            #print progress\n",
    "            bar.set_postfix(mse=float(loss))\n",
    "    # evaluate accuracy at end of each epoch\n",
    "    model.eval()\n",
    "    y_pred = model(X_test)\n",
    "    mse = loss_fn(y_pred, y_test)\n",
    "    mse = float(mse)\n",
    "    history.append(mse)\n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "        best_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "# restore model and return best accuracy\n",
    "model.load_state_dict(best_weights) \n",
    "    \n",
    " # restore model and return best accuracy\n",
    "model.load_state_dict(best_weights)\n",
    "print(\"MSE: %.2f\" % best_mse)\n",
    "print(\"RMSE: %.2f\" % np.sqrt(best_mse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the graph\n",
    "plt.plot(history)\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Non Linear Regression 1D CNN on California Housing Data](https://github.com/shreya0202/Non-Linear-Regression-1D-CNN-on-California-Housing-Data/blob/master/NLP_Assignment1.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
